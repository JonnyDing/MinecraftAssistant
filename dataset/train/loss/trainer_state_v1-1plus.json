{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 2788,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007173601147776184,
      "grad_norm": 0.9459289908409119,
      "learning_rate": 1.9999365137586883e-05,
      "loss": 2.5896,
      "step": 10
    },
    {
      "epoch": 0.014347202295552367,
      "grad_norm": 1.038580298423767,
      "learning_rate": 1.9997460630957587e-05,
      "loss": 2.596,
      "step": 20
    },
    {
      "epoch": 0.021520803443328552,
      "grad_norm": 1.6180839538574219,
      "learning_rate": 1.9994286721932043e-05,
      "loss": 2.4559,
      "step": 30
    },
    {
      "epoch": 0.028694404591104734,
      "grad_norm": 1.7194159030914307,
      "learning_rate": 1.9989843813509366e-05,
      "loss": 2.4267,
      "step": 40
    },
    {
      "epoch": 0.035868005738880916,
      "grad_norm": 1.4815353155136108,
      "learning_rate": 1.998413246981666e-05,
      "loss": 2.2658,
      "step": 50
    },
    {
      "epoch": 0.043041606886657105,
      "grad_norm": 1.6013970375061035,
      "learning_rate": 1.9977153416037424e-05,
      "loss": 2.251,
      "step": 60
    },
    {
      "epoch": 0.05021520803443329,
      "grad_norm": 1.5597803592681885,
      "learning_rate": 1.9968907538319433e-05,
      "loss": 2.2838,
      "step": 70
    },
    {
      "epoch": 0.05738880918220947,
      "grad_norm": 1.633670687675476,
      "learning_rate": 1.9959395883662257e-05,
      "loss": 2.1742,
      "step": 80
    },
    {
      "epoch": 0.06456241032998565,
      "grad_norm": 1.7283238172531128,
      "learning_rate": 1.99486196597843e-05,
      "loss": 2.0485,
      "step": 90
    },
    {
      "epoch": 0.07173601147776183,
      "grad_norm": 1.5551503896713257,
      "learning_rate": 1.993784097918207e-05,
      "loss": 2.1374,
      "step": 100
    },
    {
      "epoch": 0.07890961262553801,
      "grad_norm": 1.6347153186798096,
      "learning_rate": 1.9924665975974486e-05,
      "loss": 1.9777,
      "step": 110
    },
    {
      "epoch": 0.08608321377331421,
      "grad_norm": 2.0785748958587646,
      "learning_rate": 1.9910230813288713e-05,
      "loss": 1.9769,
      "step": 120
    },
    {
      "epoch": 0.09325681492109039,
      "grad_norm": 1.9908918142318726,
      "learning_rate": 1.9894537323993208e-05,
      "loss": 1.9754,
      "step": 130
    },
    {
      "epoch": 0.10043041606886657,
      "grad_norm": 1.9116113185882568,
      "learning_rate": 1.987758750072926e-05,
      "loss": 1.9531,
      "step": 140
    },
    {
      "epoch": 0.10760401721664276,
      "grad_norm": 1.9160429239273071,
      "learning_rate": 1.9859383495658017e-05,
      "loss": 1.9635,
      "step": 150
    },
    {
      "epoch": 0.11477761836441894,
      "grad_norm": 2.6165478229522705,
      "learning_rate": 1.983992762018719e-05,
      "loss": 1.9367,
      "step": 160
    },
    {
      "epoch": 0.12195121951219512,
      "grad_norm": 2.541781187057495,
      "learning_rate": 1.981922234467759e-05,
      "loss": 1.9123,
      "step": 170
    },
    {
      "epoch": 0.1291248206599713,
      "grad_norm": 2.04521107673645,
      "learning_rate": 1.979727029812945e-05,
      "loss": 1.8398,
      "step": 180
    },
    {
      "epoch": 0.13629842180774748,
      "grad_norm": 2.348961591720581,
      "learning_rate": 1.9774074267848626e-05,
      "loss": 1.8597,
      "step": 190
    },
    {
      "epoch": 0.14347202295552366,
      "grad_norm": 2.389742374420166,
      "learning_rate": 1.9749637199092668e-05,
      "loss": 1.7876,
      "step": 200
    },
    {
      "epoch": 0.15064562410329985,
      "grad_norm": 2.0993285179138184,
      "learning_rate": 1.9723962194696854e-05,
      "loss": 1.8308,
      "step": 210
    },
    {
      "epoch": 0.15781922525107603,
      "grad_norm": 2.264596700668335,
      "learning_rate": 1.9697052514680245e-05,
      "loss": 1.8469,
      "step": 220
    },
    {
      "epoch": 0.1649928263988522,
      "grad_norm": 1.8420758247375488,
      "learning_rate": 1.9668911575831714e-05,
      "loss": 1.8298,
      "step": 230
    },
    {
      "epoch": 0.17216642754662842,
      "grad_norm": 1.8998563289642334,
      "learning_rate": 1.9639542951276132e-05,
      "loss": 1.8329,
      "step": 240
    },
    {
      "epoch": 0.1793400286944046,
      "grad_norm": 2.053460121154785,
      "learning_rate": 1.9608950370020673e-05,
      "loss": 1.8154,
      "step": 250
    },
    {
      "epoch": 0.18651362984218078,
      "grad_norm": 2.2504353523254395,
      "learning_rate": 1.9577137716481318e-05,
      "loss": 1.8008,
      "step": 260
    },
    {
      "epoch": 0.19368723098995697,
      "grad_norm": 2.620734453201294,
      "learning_rate": 1.954410902998968e-05,
      "loss": 1.8121,
      "step": 270
    },
    {
      "epoch": 0.20086083213773315,
      "grad_norm": 2.496103286743164,
      "learning_rate": 1.9509868504280066e-05,
      "loss": 1.8067,
      "step": 280
    },
    {
      "epoch": 0.20803443328550933,
      "grad_norm": 2.9632797241210938,
      "learning_rate": 1.9474420486957045e-05,
      "loss": 1.8505,
      "step": 290
    },
    {
      "epoch": 0.2152080344332855,
      "grad_norm": 2.5157666206359863,
      "learning_rate": 1.9437769478943373e-05,
      "loss": 1.7377,
      "step": 300
    },
    {
      "epoch": 0.2223816355810617,
      "grad_norm": 2.4883086681365967,
      "learning_rate": 1.9399920133908528e-05,
      "loss": 1.7269,
      "step": 310
    },
    {
      "epoch": 0.22955523672883787,
      "grad_norm": 2.6716291904449463,
      "learning_rate": 1.936087725767782e-05,
      "loss": 1.7784,
      "step": 320
    },
    {
      "epoch": 0.23672883787661406,
      "grad_norm": 2.2206552028656006,
      "learning_rate": 1.9320645807622167e-05,
      "loss": 1.8285,
      "step": 330
    },
    {
      "epoch": 0.24390243902439024,
      "grad_norm": 3.049614667892456,
      "learning_rate": 1.9279230892028664e-05,
      "loss": 1.7855,
      "step": 340
    },
    {
      "epoch": 0.25107604017216645,
      "grad_norm": 2.802126169204712,
      "learning_rate": 1.9236637769451966e-05,
      "loss": 1.7508,
      "step": 350
    },
    {
      "epoch": 0.2582496413199426,
      "grad_norm": 2.30710768699646,
      "learning_rate": 1.9192871848046583e-05,
      "loss": 1.8322,
      "step": 360
    },
    {
      "epoch": 0.2654232424677188,
      "grad_norm": 2.3953630924224854,
      "learning_rate": 1.9147938684880213e-05,
      "loss": 1.7305,
      "step": 370
    },
    {
      "epoch": 0.27259684361549497,
      "grad_norm": 2.4712531566619873,
      "learning_rate": 1.9101843985228133e-05,
      "loss": 1.7057,
      "step": 380
    },
    {
      "epoch": 0.2797704447632712,
      "grad_norm": 2.05456805229187,
      "learning_rate": 1.9054593601848798e-05,
      "loss": 1.7569,
      "step": 390
    },
    {
      "epoch": 0.28694404591104733,
      "grad_norm": 2.7902514934539795,
      "learning_rate": 1.9006193534240687e-05,
      "loss": 1.7405,
      "step": 400
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 2.4122095108032227,
      "learning_rate": 1.8956649927880543e-05,
      "loss": 1.7214,
      "step": 410
    },
    {
      "epoch": 0.3012912482065997,
      "grad_norm": 2.6704916954040527,
      "learning_rate": 1.890596907344307e-05,
      "loss": 1.7527,
      "step": 420
    },
    {
      "epoch": 0.3084648493543759,
      "grad_norm": 2.656708002090454,
      "learning_rate": 1.8854157406002166e-05,
      "loss": 1.7105,
      "step": 430
    },
    {
      "epoch": 0.31563845050215206,
      "grad_norm": 2.830338478088379,
      "learning_rate": 1.8801221504213885e-05,
      "loss": 1.6955,
      "step": 440
    },
    {
      "epoch": 0.32281205164992827,
      "grad_norm": 2.8365447521209717,
      "learning_rate": 1.8747168089481094e-05,
      "loss": 1.7487,
      "step": 450
    },
    {
      "epoch": 0.3299856527977044,
      "grad_norm": 2.810979127883911,
      "learning_rate": 1.8692004025100054e-05,
      "loss": 1.7252,
      "step": 460
    },
    {
      "epoch": 0.33715925394548063,
      "grad_norm": 2.6045217514038086,
      "learning_rate": 1.8635736315388974e-05,
      "loss": 1.7363,
      "step": 470
    },
    {
      "epoch": 0.34433285509325684,
      "grad_norm": 2.833042621612549,
      "learning_rate": 1.8578372104798645e-05,
      "loss": 1.7959,
      "step": 480
    },
    {
      "epoch": 0.351506456241033,
      "grad_norm": 2.914783000946045,
      "learning_rate": 1.85199186770053e-05,
      "loss": 1.8051,
      "step": 490
    },
    {
      "epoch": 0.3586800573888092,
      "grad_norm": 2.7726540565490723,
      "learning_rate": 1.8460383453985784e-05,
      "loss": 1.6844,
      "step": 500
    },
    {
      "epoch": 0.36585365853658536,
      "grad_norm": 2.4892635345458984,
      "learning_rate": 1.8399773995075166e-05,
      "loss": 1.7135,
      "step": 510
    },
    {
      "epoch": 0.37302725968436157,
      "grad_norm": 2.6092724800109863,
      "learning_rate": 1.8338097996006922e-05,
      "loss": 1.6581,
      "step": 520
    },
    {
      "epoch": 0.3802008608321377,
      "grad_norm": 2.7328274250030518,
      "learning_rate": 1.827536328793576e-05,
      "loss": 1.6709,
      "step": 530
    },
    {
      "epoch": 0.38737446197991393,
      "grad_norm": 3.0924689769744873,
      "learning_rate": 1.821157783644332e-05,
      "loss": 1.7331,
      "step": 540
    },
    {
      "epoch": 0.3945480631276901,
      "grad_norm": 3.106117010116577,
      "learning_rate": 1.814674974052672e-05,
      "loss": 1.6204,
      "step": 550
    },
    {
      "epoch": 0.4017216642754663,
      "grad_norm": 2.8015565872192383,
      "learning_rate": 1.8080887231570262e-05,
      "loss": 1.71,
      "step": 560
    },
    {
      "epoch": 0.40889526542324245,
      "grad_norm": 3.4019083976745605,
      "learning_rate": 1.801399867230021e-05,
      "loss": 1.7012,
      "step": 570
    },
    {
      "epoch": 0.41606886657101866,
      "grad_norm": 2.7214784622192383,
      "learning_rate": 1.7946092555722988e-05,
      "loss": 1.7052,
      "step": 580
    },
    {
      "epoch": 0.4232424677187948,
      "grad_norm": 2.8500778675079346,
      "learning_rate": 1.787717750404681e-05,
      "loss": 1.7654,
      "step": 590
    },
    {
      "epoch": 0.430416068866571,
      "grad_norm": 2.4985532760620117,
      "learning_rate": 1.7807262267586877e-05,
      "loss": 1.6966,
      "step": 600
    },
    {
      "epoch": 0.4375896700143472,
      "grad_norm": 2.849909782409668,
      "learning_rate": 1.7736355723654334e-05,
      "loss": 1.6949,
      "step": 610
    },
    {
      "epoch": 0.4447632711621234,
      "grad_norm": 3.206366777420044,
      "learning_rate": 1.76644668754291e-05,
      "loss": 1.6866,
      "step": 620
    },
    {
      "epoch": 0.4519368723098996,
      "grad_norm": 3.6226282119750977,
      "learning_rate": 1.7591604850816705e-05,
      "loss": 1.7428,
      "step": 630
    },
    {
      "epoch": 0.45911047345767575,
      "grad_norm": 3.1167855262756348,
      "learning_rate": 1.7517778901289307e-05,
      "loss": 1.6637,
      "step": 640
    },
    {
      "epoch": 0.46628407460545196,
      "grad_norm": 3.018139123916626,
      "learning_rate": 1.7442998400710992e-05,
      "loss": 1.6693,
      "step": 650
    },
    {
      "epoch": 0.4734576757532281,
      "grad_norm": 3.1553211212158203,
      "learning_rate": 1.736727284414758e-05,
      "loss": 1.7161,
      "step": 660
    },
    {
      "epoch": 0.4806312769010043,
      "grad_norm": 4.1328630447387695,
      "learning_rate": 1.7290611846660978e-05,
      "loss": 1.6783,
      "step": 670
    },
    {
      "epoch": 0.4878048780487805,
      "grad_norm": 3.2036681175231934,
      "learning_rate": 1.7213025142088362e-05,
      "loss": 1.6385,
      "step": 680
    },
    {
      "epoch": 0.4949784791965567,
      "grad_norm": 3.408390522003174,
      "learning_rate": 1.7134522581806227e-05,
      "loss": 1.7289,
      "step": 690
    },
    {
      "epoch": 0.5021520803443329,
      "grad_norm": 3.300092935562134,
      "learning_rate": 1.705511413347954e-05,
      "loss": 1.7008,
      "step": 700
    },
    {
      "epoch": 0.509325681492109,
      "grad_norm": 3.2592577934265137,
      "learning_rate": 1.6974809879796138e-05,
      "loss": 1.6828,
      "step": 710
    },
    {
      "epoch": 0.5164992826398852,
      "grad_norm": 3.123706102371216,
      "learning_rate": 1.6893620017186473e-05,
      "loss": 1.7437,
      "step": 720
    },
    {
      "epoch": 0.5236728837876614,
      "grad_norm": 2.927600145339966,
      "learning_rate": 1.681155485452896e-05,
      "loss": 1.6808,
      "step": 730
    },
    {
      "epoch": 0.5308464849354376,
      "grad_norm": 3.1998825073242188,
      "learning_rate": 1.6728624811841036e-05,
      "loss": 1.742,
      "step": 740
    },
    {
      "epoch": 0.5380200860832137,
      "grad_norm": 3.1038053035736084,
      "learning_rate": 1.6644840418956116e-05,
      "loss": 1.6458,
      "step": 750
    },
    {
      "epoch": 0.5451936872309899,
      "grad_norm": 3.3894622325897217,
      "learning_rate": 1.656021231418656e-05,
      "loss": 1.6591,
      "step": 760
    },
    {
      "epoch": 0.5523672883787661,
      "grad_norm": 3.922757863998413,
      "learning_rate": 1.6474751242972932e-05,
      "loss": 1.6236,
      "step": 770
    },
    {
      "epoch": 0.5595408895265424,
      "grad_norm": 4.005507946014404,
      "learning_rate": 1.638846805651961e-05,
      "loss": 1.743,
      "step": 780
    },
    {
      "epoch": 0.5667144906743186,
      "grad_norm": 2.9647035598754883,
      "learning_rate": 1.6301373710416998e-05,
      "loss": 1.6892,
      "step": 790
    },
    {
      "epoch": 0.5738880918220947,
      "grad_norm": 2.798293352127075,
      "learning_rate": 1.6213479263250433e-05,
      "loss": 1.6588,
      "step": 800
    },
    {
      "epoch": 0.5810616929698709,
      "grad_norm": 3.46358585357666,
      "learning_rate": 1.6124795875196083e-05,
      "loss": 1.6515,
      "step": 810
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 3.0845093727111816,
      "learning_rate": 1.6035334806603894e-05,
      "loss": 1.6469,
      "step": 820
    },
    {
      "epoch": 0.5954088952654233,
      "grad_norm": 3.229746103286743,
      "learning_rate": 1.5945107416567846e-05,
      "loss": 1.7056,
      "step": 830
    },
    {
      "epoch": 0.6025824964131994,
      "grad_norm": 3.0416982173919678,
      "learning_rate": 1.585412516148365e-05,
      "loss": 1.6391,
      "step": 840
    },
    {
      "epoch": 0.6097560975609756,
      "grad_norm": 2.987957000732422,
      "learning_rate": 1.5762399593594114e-05,
      "loss": 1.5997,
      "step": 850
    },
    {
      "epoch": 0.6169296987087518,
      "grad_norm": 3.201866626739502,
      "learning_rate": 1.566994235952231e-05,
      "loss": 1.724,
      "step": 860
    },
    {
      "epoch": 0.624103299856528,
      "grad_norm": 3.804136276245117,
      "learning_rate": 1.5576765198792782e-05,
      "loss": 1.6816,
      "step": 870
    },
    {
      "epoch": 0.6312769010043041,
      "grad_norm": 3.4923996925354004,
      "learning_rate": 1.5482879942340955e-05,
      "loss": 1.6652,
      "step": 880
    },
    {
      "epoch": 0.6384505021520803,
      "grad_norm": 3.5395736694335938,
      "learning_rate": 1.5388298511010922e-05,
      "loss": 1.6725,
      "step": 890
    },
    {
      "epoch": 0.6456241032998565,
      "grad_norm": 3.6179685592651367,
      "learning_rate": 1.529303291404183e-05,
      "loss": 1.6961,
      "step": 900
    },
    {
      "epoch": 0.6527977044476327,
      "grad_norm": 3.9681923389434814,
      "learning_rate": 1.5197095247543034e-05,
      "loss": 1.6027,
      "step": 910
    },
    {
      "epoch": 0.6599713055954088,
      "grad_norm": 3.709033727645874,
      "learning_rate": 1.5100497692958222e-05,
      "loss": 1.739,
      "step": 920
    },
    {
      "epoch": 0.667144906743185,
      "grad_norm": 3.1956419944763184,
      "learning_rate": 1.5003252515518725e-05,
      "loss": 1.6134,
      "step": 930
    },
    {
      "epoch": 0.6743185078909613,
      "grad_norm": 3.599987506866455,
      "learning_rate": 1.4905372062686135e-05,
      "loss": 1.6411,
      "step": 940
    },
    {
      "epoch": 0.6814921090387375,
      "grad_norm": 3.4680142402648926,
      "learning_rate": 1.4806868762584551e-05,
      "loss": 1.6794,
      "step": 950
    },
    {
      "epoch": 0.6886657101865137,
      "grad_norm": 3.2577743530273438,
      "learning_rate": 1.470775512242254e-05,
      "loss": 1.6086,
      "step": 960
    },
    {
      "epoch": 0.6958393113342898,
      "grad_norm": 2.6975395679473877,
      "learning_rate": 1.460804372690505e-05,
      "loss": 1.6461,
      "step": 970
    },
    {
      "epoch": 0.703012912482066,
      "grad_norm": 3.298818349838257,
      "learning_rate": 1.4507747236635517e-05,
      "loss": 1.7056,
      "step": 980
    },
    {
      "epoch": 0.7101865136298422,
      "grad_norm": 3.8594415187835693,
      "learning_rate": 1.4406878386508307e-05,
      "loss": 1.6505,
      "step": 990
    },
    {
      "epoch": 0.7173601147776184,
      "grad_norm": 3.394050359725952,
      "learning_rate": 1.430544998409174e-05,
      "loss": 1.5751,
      "step": 1000
    },
    {
      "epoch": 0.7245337159253945,
      "grad_norm": 3.12233567237854,
      "learning_rate": 1.4203474908001883e-05,
      "loss": 1.6383,
      "step": 1010
    },
    {
      "epoch": 0.7317073170731707,
      "grad_norm": 3.071113109588623,
      "learning_rate": 1.4100966106267313e-05,
      "loss": 1.6289,
      "step": 1020
    },
    {
      "epoch": 0.7388809182209469,
      "grad_norm": 3.182933807373047,
      "learning_rate": 1.3997936594685073e-05,
      "loss": 1.6671,
      "step": 1030
    },
    {
      "epoch": 0.7460545193687231,
      "grad_norm": 4.318474292755127,
      "learning_rate": 1.3894399455168032e-05,
      "loss": 1.6357,
      "step": 1040
    },
    {
      "epoch": 0.7532281205164992,
      "grad_norm": 3.32720685005188,
      "learning_rate": 1.3790367834083842e-05,
      "loss": 1.6105,
      "step": 1050
    },
    {
      "epoch": 0.7604017216642754,
      "grad_norm": 3.2429604530334473,
      "learning_rate": 1.3685854940585705e-05,
      "loss": 1.6523,
      "step": 1060
    },
    {
      "epoch": 0.7675753228120517,
      "grad_norm": 3.192425012588501,
      "learning_rate": 1.3580874044935167e-05,
      "loss": 1.6331,
      "step": 1070
    },
    {
      "epoch": 0.7747489239598279,
      "grad_norm": 3.4372947216033936,
      "learning_rate": 1.3475438476817183e-05,
      "loss": 1.6654,
      "step": 1080
    },
    {
      "epoch": 0.7819225251076041,
      "grad_norm": 3.2402994632720947,
      "learning_rate": 1.3369561623647589e-05,
      "loss": 1.74,
      "step": 1090
    },
    {
      "epoch": 0.7890961262553802,
      "grad_norm": 3.59602689743042,
      "learning_rate": 1.326325692887329e-05,
      "loss": 1.6433,
      "step": 1100
    },
    {
      "epoch": 0.7962697274031564,
      "grad_norm": 3.6668341159820557,
      "learning_rate": 1.3156537890265293e-05,
      "loss": 1.6348,
      "step": 1110
    },
    {
      "epoch": 0.8034433285509326,
      "grad_norm": 3.297494649887085,
      "learning_rate": 1.304941805820487e-05,
      "loss": 1.6267,
      "step": 1120
    },
    {
      "epoch": 0.8106169296987088,
      "grad_norm": 3.587001085281372,
      "learning_rate": 1.2941911033963042e-05,
      "loss": 1.5774,
      "step": 1130
    },
    {
      "epoch": 0.8177905308464849,
      "grad_norm": 3.7440712451934814,
      "learning_rate": 1.2834030467973572e-05,
      "loss": 1.6093,
      "step": 1140
    },
    {
      "epoch": 0.8249641319942611,
      "grad_norm": 3.4788947105407715,
      "learning_rate": 1.2725790058099754e-05,
      "loss": 1.5475,
      "step": 1150
    },
    {
      "epoch": 0.8321377331420373,
      "grad_norm": 4.006147861480713,
      "learning_rate": 1.2617203547895147e-05,
      "loss": 1.6783,
      "step": 1160
    },
    {
      "epoch": 0.8393113342898135,
      "grad_norm": 3.5110161304473877,
      "learning_rate": 1.2508284724858534e-05,
      "loss": 1.6232,
      "step": 1170
    },
    {
      "epoch": 0.8464849354375896,
      "grad_norm": 2.8880836963653564,
      "learning_rate": 1.239904741868328e-05,
      "loss": 1.6472,
      "step": 1180
    },
    {
      "epoch": 0.8536585365853658,
      "grad_norm": 3.890367031097412,
      "learning_rate": 1.2289505499501341e-05,
      "loss": 1.6469,
      "step": 1190
    },
    {
      "epoch": 0.860832137733142,
      "grad_norm": 3.706843852996826,
      "learning_rate": 1.2179672876122152e-05,
      "loss": 1.5987,
      "step": 1200
    },
    {
      "epoch": 0.8680057388809183,
      "grad_norm": 3.77972674369812,
      "learning_rate": 1.2069563494266574e-05,
      "loss": 1.6686,
      "step": 1210
    },
    {
      "epoch": 0.8751793400286944,
      "grad_norm": 3.778947114944458,
      "learning_rate": 1.195919133479618e-05,
      "loss": 1.644,
      "step": 1220
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 3.0403835773468018,
      "learning_rate": 1.1848570411938077e-05,
      "loss": 1.6367,
      "step": 1230
    },
    {
      "epoch": 0.8895265423242468,
      "grad_norm": 3.9170734882354736,
      "learning_rate": 1.173771477150546e-05,
      "loss": 1.6369,
      "step": 1240
    },
    {
      "epoch": 0.896700143472023,
      "grad_norm": 3.782606840133667,
      "learning_rate": 1.1626638489114216e-05,
      "loss": 1.6688,
      "step": 1250
    },
    {
      "epoch": 0.9038737446197992,
      "grad_norm": 3.364636182785034,
      "learning_rate": 1.1515355668395676e-05,
      "loss": 1.7292,
      "step": 1260
    },
    {
      "epoch": 0.9110473457675753,
      "grad_norm": 3.777991771697998,
      "learning_rate": 1.1403880439205863e-05,
      "loss": 1.6706,
      "step": 1270
    },
    {
      "epoch": 0.9182209469153515,
      "grad_norm": 3.720698833465576,
      "learning_rate": 1.1292226955831378e-05,
      "loss": 1.766,
      "step": 1280
    },
    {
      "epoch": 0.9253945480631277,
      "grad_norm": 4.273490905761719,
      "learning_rate": 1.1180409395192197e-05,
      "loss": 1.6542,
      "step": 1290
    },
    {
      "epoch": 0.9325681492109039,
      "grad_norm": 3.7430837154388428,
      "learning_rate": 1.1068441955041596e-05,
      "loss": 1.6197,
      "step": 1300
    },
    {
      "epoch": 0.93974175035868,
      "grad_norm": 3.724963903427124,
      "learning_rate": 1.0956338852163424e-05,
      "loss": 1.6316,
      "step": 1310
    },
    {
      "epoch": 0.9469153515064562,
      "grad_norm": 3.529618501663208,
      "learning_rate": 1.0844114320566963e-05,
      "loss": 1.6514,
      "step": 1320
    },
    {
      "epoch": 0.9540889526542324,
      "grad_norm": 3.5527889728546143,
      "learning_rate": 1.0731782609679601e-05,
      "loss": 1.5632,
      "step": 1330
    },
    {
      "epoch": 0.9612625538020086,
      "grad_norm": 3.579197645187378,
      "learning_rate": 1.061935798253755e-05,
      "loss": 1.6613,
      "step": 1340
    },
    {
      "epoch": 0.9684361549497847,
      "grad_norm": 3.8306052684783936,
      "learning_rate": 1.0506854713974822e-05,
      "loss": 1.571,
      "step": 1350
    },
    {
      "epoch": 0.975609756097561,
      "grad_norm": 3.2510387897491455,
      "learning_rate": 1.0394287088810733e-05,
      "loss": 1.59,
      "step": 1360
    },
    {
      "epoch": 0.9827833572453372,
      "grad_norm": 4.156473159790039,
      "learning_rate": 1.0281669400036109e-05,
      "loss": 1.5988,
      "step": 1370
    },
    {
      "epoch": 0.9899569583931134,
      "grad_norm": 3.3383893966674805,
      "learning_rate": 1.0169015946998485e-05,
      "loss": 1.6812,
      "step": 1380
    },
    {
      "epoch": 0.9971305595408895,
      "grad_norm": 4.122254371643066,
      "learning_rate": 1.0056341033586463e-05,
      "loss": 1.6661,
      "step": 1390
    },
    {
      "epoch": 1.0043041606886658,
      "grad_norm": 3.8375730514526367,
      "learning_rate": 9.943658966413537e-06,
      "loss": 1.644,
      "step": 1400
    },
    {
      "epoch": 1.011477761836442,
      "grad_norm": 3.2813587188720703,
      "learning_rate": 9.83098405300152e-06,
      "loss": 1.5853,
      "step": 1410
    },
    {
      "epoch": 1.018651362984218,
      "grad_norm": 4.099836826324463,
      "learning_rate": 9.718330599963896e-06,
      "loss": 1.5464,
      "step": 1420
    },
    {
      "epoch": 1.0258249641319943,
      "grad_norm": 3.9552948474884033,
      "learning_rate": 9.60571291118927e-06,
      "loss": 1.6472,
      "step": 1430
    },
    {
      "epoch": 1.0329985652797704,
      "grad_norm": 3.56933331489563,
      "learning_rate": 9.493145286025181e-06,
      "loss": 1.594,
      "step": 1440
    },
    {
      "epoch": 1.0401721664275467,
      "grad_norm": 4.696218013763428,
      "learning_rate": 9.38064201746245e-06,
      "loss": 1.6075,
      "step": 1450
    },
    {
      "epoch": 1.0473457675753228,
      "grad_norm": 4.000743389129639,
      "learning_rate": 9.2682173903204e-06,
      "loss": 1.5651,
      "step": 1460
    },
    {
      "epoch": 1.054519368723099,
      "grad_norm": 4.1521124839782715,
      "learning_rate": 9.155885679433039e-06,
      "loss": 1.6432,
      "step": 1470
    },
    {
      "epoch": 1.0616929698708752,
      "grad_norm": 4.100081443786621,
      "learning_rate": 9.043661147836578e-06,
      "loss": 1.6451,
      "step": 1480
    },
    {
      "epoch": 1.0688665710186513,
      "grad_norm": 3.493873357772827,
      "learning_rate": 8.931558044958408e-06,
      "loss": 1.6001,
      "step": 1490
    },
    {
      "epoch": 1.0760401721664274,
      "grad_norm": 4.01984167098999,
      "learning_rate": 8.819590604807806e-06,
      "loss": 1.5602,
      "step": 1500
    },
    {
      "epoch": 1.0832137733142038,
      "grad_norm": 3.645911455154419,
      "learning_rate": 8.707773044168626e-06,
      "loss": 1.5665,
      "step": 1510
    },
    {
      "epoch": 1.0903873744619799,
      "grad_norm": 4.47953987121582,
      "learning_rate": 8.59611956079414e-06,
      "loss": 1.6667,
      "step": 1520
    },
    {
      "epoch": 1.0975609756097562,
      "grad_norm": 3.720404863357544,
      "learning_rate": 8.484644331604326e-06,
      "loss": 1.5594,
      "step": 1530
    },
    {
      "epoch": 1.1047345767575323,
      "grad_norm": 3.7896838188171387,
      "learning_rate": 8.37336151088579e-06,
      "loss": 1.5678,
      "step": 1540
    },
    {
      "epoch": 1.1119081779053084,
      "grad_norm": 4.416505336761475,
      "learning_rate": 8.262285228494545e-06,
      "loss": 1.5399,
      "step": 1550
    },
    {
      "epoch": 1.1190817790530847,
      "grad_norm": 3.4337921142578125,
      "learning_rate": 8.151429588061928e-06,
      "loss": 1.5971,
      "step": 1560
    },
    {
      "epoch": 1.1262553802008608,
      "grad_norm": 3.4985198974609375,
      "learning_rate": 8.040808665203823e-06,
      "loss": 1.6127,
      "step": 1570
    },
    {
      "epoch": 1.133428981348637,
      "grad_norm": 3.590985059738159,
      "learning_rate": 7.930436505733428e-06,
      "loss": 1.5745,
      "step": 1580
    },
    {
      "epoch": 1.1406025824964132,
      "grad_norm": 3.582629919052124,
      "learning_rate": 7.820327123877851e-06,
      "loss": 1.5829,
      "step": 1590
    },
    {
      "epoch": 1.1477761836441893,
      "grad_norm": 3.5689873695373535,
      "learning_rate": 7.710494500498662e-06,
      "loss": 1.5531,
      "step": 1600
    },
    {
      "epoch": 1.1549497847919656,
      "grad_norm": 2.7556393146514893,
      "learning_rate": 7.600952581316723e-06,
      "loss": 1.6635,
      "step": 1610
    },
    {
      "epoch": 1.1621233859397417,
      "grad_norm": 3.7920782566070557,
      "learning_rate": 7.491715275141469e-06,
      "loss": 1.5951,
      "step": 1620
    },
    {
      "epoch": 1.169296987087518,
      "grad_norm": 4.238959312438965,
      "learning_rate": 7.382796452104853e-06,
      "loss": 1.6224,
      "step": 1630
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 3.4483249187469482,
      "learning_rate": 7.274209941900248e-06,
      "loss": 1.6229,
      "step": 1640
    },
    {
      "epoch": 1.1836441893830703,
      "grad_norm": 3.7541110515594482,
      "learning_rate": 7.16596953202643e-06,
      "loss": 1.5704,
      "step": 1650
    },
    {
      "epoch": 1.1908177905308466,
      "grad_norm": 3.281494379043579,
      "learning_rate": 7.058088966036961e-06,
      "loss": 1.5747,
      "step": 1660
    },
    {
      "epoch": 1.1979913916786227,
      "grad_norm": 3.947143793106079,
      "learning_rate": 6.9505819417951315e-06,
      "loss": 1.6599,
      "step": 1670
    },
    {
      "epoch": 1.2051649928263988,
      "grad_norm": 4.257234573364258,
      "learning_rate": 6.843462109734713e-06,
      "loss": 1.634,
      "step": 1680
    },
    {
      "epoch": 1.212338593974175,
      "grad_norm": 3.1467032432556152,
      "learning_rate": 6.736743071126712e-06,
      "loss": 1.6159,
      "step": 1690
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 3.7314722537994385,
      "learning_rate": 6.630438376352415e-06,
      "loss": 1.5732,
      "step": 1700
    },
    {
      "epoch": 1.2266857962697273,
      "grad_norm": 3.8023500442504883,
      "learning_rate": 6.52456152318282e-06,
      "loss": 1.6578,
      "step": 1710
    },
    {
      "epoch": 1.2338593974175036,
      "grad_norm": 3.774657726287842,
      "learning_rate": 6.419125955064836e-06,
      "loss": 1.5905,
      "step": 1720
    },
    {
      "epoch": 1.2410329985652797,
      "grad_norm": 4.203271865844727,
      "learning_rate": 6.3141450594143e-06,
      "loss": 1.5823,
      "step": 1730
    },
    {
      "epoch": 1.248206599713056,
      "grad_norm": 4.818375587463379,
      "learning_rate": 6.209632165916157e-06,
      "loss": 1.5883,
      "step": 1740
    },
    {
      "epoch": 1.2553802008608321,
      "grad_norm": 3.675914764404297,
      "learning_rate": 6.105600544831969e-06,
      "loss": 1.5465,
      "step": 1750
    },
    {
      "epoch": 1.2625538020086085,
      "grad_norm": 4.489685535430908,
      "learning_rate": 6.002063405314932e-06,
      "loss": 1.6567,
      "step": 1760
    },
    {
      "epoch": 1.2697274031563845,
      "grad_norm": 4.799049377441406,
      "learning_rate": 5.899033893732688e-06,
      "loss": 1.6497,
      "step": 1770
    },
    {
      "epoch": 1.2769010043041606,
      "grad_norm": 4.19090461730957,
      "learning_rate": 5.796525091998117e-06,
      "loss": 1.6293,
      "step": 1780
    },
    {
      "epoch": 1.284074605451937,
      "grad_norm": 4.057677268981934,
      "learning_rate": 5.6945500159082575e-06,
      "loss": 1.5755,
      "step": 1790
    },
    {
      "epoch": 1.291248206599713,
      "grad_norm": 3.2478389739990234,
      "learning_rate": 5.593121613491694e-06,
      "loss": 1.6295,
      "step": 1800
    },
    {
      "epoch": 1.2984218077474892,
      "grad_norm": 4.768766403198242,
      "learning_rate": 5.492252763364487e-06,
      "loss": 1.5419,
      "step": 1810
    },
    {
      "epoch": 1.3055954088952655,
      "grad_norm": 4.195352077484131,
      "learning_rate": 5.391956273094952e-06,
      "loss": 1.5794,
      "step": 1820
    },
    {
      "epoch": 1.3127690100430416,
      "grad_norm": 3.904062271118164,
      "learning_rate": 5.292244877577461e-06,
      "loss": 1.5701,
      "step": 1830
    },
    {
      "epoch": 1.3199426111908177,
      "grad_norm": 4.292078495025635,
      "learning_rate": 5.193131237415448e-06,
      "loss": 1.5751,
      "step": 1840
    },
    {
      "epoch": 1.327116212338594,
      "grad_norm": 4.093900203704834,
      "learning_rate": 5.0946279373138675e-06,
      "loss": 1.6081,
      "step": 1850
    },
    {
      "epoch": 1.33428981348637,
      "grad_norm": 4.204676151275635,
      "learning_rate": 4.9967474844812806e-06,
      "loss": 1.6169,
      "step": 1860
    },
    {
      "epoch": 1.3414634146341464,
      "grad_norm": 3.874249219894409,
      "learning_rate": 4.899502307041778e-06,
      "loss": 1.5278,
      "step": 1870
    },
    {
      "epoch": 1.3486370157819225,
      "grad_norm": 4.168915271759033,
      "learning_rate": 4.80290475245697e-06,
      "loss": 1.6601,
      "step": 1880
    },
    {
      "epoch": 1.3558106169296988,
      "grad_norm": 3.7881100177764893,
      "learning_rate": 4.706967085958174e-06,
      "loss": 1.6074,
      "step": 1890
    },
    {
      "epoch": 1.362984218077475,
      "grad_norm": 4.09196662902832,
      "learning_rate": 4.611701488989078e-06,
      "loss": 1.6695,
      "step": 1900
    },
    {
      "epoch": 1.370157819225251,
      "grad_norm": 4.457287788391113,
      "learning_rate": 4.517120057659048e-06,
      "loss": 1.6217,
      "step": 1910
    },
    {
      "epoch": 1.3773314203730274,
      "grad_norm": 3.798954486846924,
      "learning_rate": 4.423234801207219e-06,
      "loss": 1.6626,
      "step": 1920
    },
    {
      "epoch": 1.3845050215208035,
      "grad_norm": 3.690166711807251,
      "learning_rate": 4.330057640477694e-06,
      "loss": 1.5898,
      "step": 1930
    },
    {
      "epoch": 1.3916786226685796,
      "grad_norm": 4.089950084686279,
      "learning_rate": 4.2376004064058904e-06,
      "loss": 1.6128,
      "step": 1940
    },
    {
      "epoch": 1.3988522238163559,
      "grad_norm": 4.275885105133057,
      "learning_rate": 4.145874838516351e-06,
      "loss": 1.6031,
      "step": 1950
    },
    {
      "epoch": 1.406025824964132,
      "grad_norm": 3.975090265274048,
      "learning_rate": 4.054892583432159e-06,
      "loss": 1.5923,
      "step": 1960
    },
    {
      "epoch": 1.413199426111908,
      "grad_norm": 4.515425205230713,
      "learning_rate": 3.964665193396109e-06,
      "loss": 1.6089,
      "step": 1970
    },
    {
      "epoch": 1.4203730272596844,
      "grad_norm": 4.331508636474609,
      "learning_rate": 3.875204124803921e-06,
      "loss": 1.4802,
      "step": 1980
    },
    {
      "epoch": 1.4275466284074605,
      "grad_norm": 4.94050931930542,
      "learning_rate": 3.7865207367495716e-06,
      "loss": 1.6772,
      "step": 1990
    },
    {
      "epoch": 1.4347202295552366,
      "grad_norm": 4.074823379516602,
      "learning_rate": 3.698626289583004e-06,
      "loss": 1.5725,
      "step": 2000
    },
    {
      "epoch": 1.441893830703013,
      "grad_norm": 4.066888332366943,
      "learning_rate": 3.6115319434803897e-06,
      "loss": 1.7159,
      "step": 2010
    },
    {
      "epoch": 1.4490674318507892,
      "grad_norm": 3.678567886352539,
      "learning_rate": 3.525248757027073e-06,
      "loss": 1.5384,
      "step": 2020
    },
    {
      "epoch": 1.4562410329985653,
      "grad_norm": 3.9218077659606934,
      "learning_rate": 3.439787685813445e-06,
      "loss": 1.5933,
      "step": 2030
    },
    {
      "epoch": 1.4634146341463414,
      "grad_norm": 5.126521110534668,
      "learning_rate": 3.3551595810438898e-06,
      "loss": 1.7293,
      "step": 2040
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 4.167481899261475,
      "learning_rate": 3.271375188158964e-06,
      "loss": 1.6818,
      "step": 2050
    },
    {
      "epoch": 1.4777618364418939,
      "grad_norm": 4.091371536254883,
      "learning_rate": 3.188445145471045e-06,
      "loss": 1.6325,
      "step": 2060
    },
    {
      "epoch": 1.48493543758967,
      "grad_norm": 4.0771942138671875,
      "learning_rate": 3.106379982813529e-06,
      "loss": 1.5659,
      "step": 2070
    },
    {
      "epoch": 1.4921090387374463,
      "grad_norm": 4.156938076019287,
      "learning_rate": 3.0251901202038592e-06,
      "loss": 1.5344,
      "step": 2080
    },
    {
      "epoch": 1.4992826398852224,
      "grad_norm": 4.4307732582092285,
      "learning_rate": 2.944885866520457e-06,
      "loss": 1.6268,
      "step": 2090
    },
    {
      "epoch": 1.5064562410329985,
      "grad_norm": 4.5665998458862305,
      "learning_rate": 2.865477418193774e-06,
      "loss": 1.5705,
      "step": 2100
    },
    {
      "epoch": 1.5136298421807748,
      "grad_norm": 3.3981597423553467,
      "learning_rate": 2.7869748579116407e-06,
      "loss": 1.574,
      "step": 2110
    },
    {
      "epoch": 1.5208034433285509,
      "grad_norm": 4.455482482910156,
      "learning_rate": 2.7093881533390245e-06,
      "loss": 1.5595,
      "step": 2120
    },
    {
      "epoch": 1.527977044476327,
      "grad_norm": 4.464920520782471,
      "learning_rate": 2.6327271558524202e-06,
      "loss": 1.6129,
      "step": 2130
    },
    {
      "epoch": 1.5351506456241033,
      "grad_norm": 4.370522499084473,
      "learning_rate": 2.5570015992890074e-06,
      "loss": 1.5964,
      "step": 2140
    },
    {
      "epoch": 1.5423242467718796,
      "grad_norm": 3.9745428562164307,
      "learning_rate": 2.4822210987106964e-06,
      "loss": 1.5658,
      "step": 2150
    },
    {
      "epoch": 1.5494978479196555,
      "grad_norm": 4.227618217468262,
      "learning_rate": 2.4083951491832947e-06,
      "loss": 1.5426,
      "step": 2160
    },
    {
      "epoch": 1.5566714490674318,
      "grad_norm": 4.053417205810547,
      "learning_rate": 2.3355331245709013e-06,
      "loss": 1.5496,
      "step": 2170
    },
    {
      "epoch": 1.5638450502152081,
      "grad_norm": 4.553435325622559,
      "learning_rate": 2.2636442763456656e-06,
      "loss": 1.6138,
      "step": 2180
    },
    {
      "epoch": 1.5710186513629842,
      "grad_norm": 4.427667140960693,
      "learning_rate": 2.192737732413125e-06,
      "loss": 1.6018,
      "step": 2190
    },
    {
      "epoch": 1.5781922525107603,
      "grad_norm": 3.793785333633423,
      "learning_rate": 2.122822495953193e-06,
      "loss": 1.5933,
      "step": 2200
    },
    {
      "epoch": 1.5853658536585367,
      "grad_norm": 4.691203594207764,
      "learning_rate": 2.0539074442770148e-06,
      "loss": 1.5872,
      "step": 2210
    },
    {
      "epoch": 1.5925394548063128,
      "grad_norm": 4.4067511558532715,
      "learning_rate": 1.9860013276997957e-06,
      "loss": 1.6238,
      "step": 2220
    },
    {
      "epoch": 1.5997130559540889,
      "grad_norm": 4.2028117179870605,
      "learning_rate": 1.919112768429742e-06,
      "loss": 1.5941,
      "step": 2230
    },
    {
      "epoch": 1.6068866571018652,
      "grad_norm": 5.274405002593994,
      "learning_rate": 1.8532502594732792e-06,
      "loss": 1.626,
      "step": 2240
    },
    {
      "epoch": 1.6140602582496413,
      "grad_norm": 5.411527156829834,
      "learning_rate": 1.7884221635566867e-06,
      "loss": 1.6224,
      "step": 2250
    },
    {
      "epoch": 1.6212338593974174,
      "grad_norm": 4.933219909667969,
      "learning_rate": 1.7246367120642438e-06,
      "loss": 1.5873,
      "step": 2260
    },
    {
      "epoch": 1.6284074605451937,
      "grad_norm": 3.8100500106811523,
      "learning_rate": 1.6619020039930833e-06,
      "loss": 1.617,
      "step": 2270
    },
    {
      "epoch": 1.63558106169297,
      "grad_norm": 4.3861918449401855,
      "learning_rate": 1.6002260049248364e-06,
      "loss": 1.642,
      "step": 2280
    },
    {
      "epoch": 1.642754662840746,
      "grad_norm": 4.339298725128174,
      "learning_rate": 1.5396165460142186e-06,
      "loss": 1.5679,
      "step": 2290
    },
    {
      "epoch": 1.6499282639885222,
      "grad_norm": 4.073395729064941,
      "learning_rate": 1.4800813229947043e-06,
      "loss": 1.5916,
      "step": 2300
    },
    {
      "epoch": 1.6571018651362985,
      "grad_norm": 4.506665229797363,
      "learning_rate": 1.4216278952013575e-06,
      "loss": 1.5675,
      "step": 2310
    },
    {
      "epoch": 1.6642754662840746,
      "grad_norm": 4.499811172485352,
      "learning_rate": 1.364263684611029e-06,
      "loss": 1.6554,
      "step": 2320
    },
    {
      "epoch": 1.6714490674318507,
      "grad_norm": 4.696051120758057,
      "learning_rate": 1.3079959748999494e-06,
      "loss": 1.6204,
      "step": 2330
    },
    {
      "epoch": 1.678622668579627,
      "grad_norm": 3.631579637527466,
      "learning_rate": 1.2528319105189079e-06,
      "loss": 1.5806,
      "step": 2340
    },
    {
      "epoch": 1.6857962697274032,
      "grad_norm": 4.601315975189209,
      "learning_rate": 1.198778495786117e-06,
      "loss": 1.5943,
      "step": 2350
    },
    {
      "epoch": 1.6929698708751793,
      "grad_norm": 4.75112247467041,
      "learning_rate": 1.1458425939978346e-06,
      "loss": 1.647,
      "step": 2360
    },
    {
      "epoch": 1.7001434720229556,
      "grad_norm": 4.626829147338867,
      "learning_rate": 1.094030926556935e-06,
      "loss": 1.6236,
      "step": 2370
    },
    {
      "epoch": 1.7073170731707317,
      "grad_norm": 4.237418174743652,
      "learning_rate": 1.0433500721194579e-06,
      "loss": 1.5468,
      "step": 2380
    },
    {
      "epoch": 1.7144906743185078,
      "grad_norm": 4.568727493286133,
      "learning_rate": 9.93806465759316e-07,
      "loss": 1.5437,
      "step": 2390
    },
    {
      "epoch": 1.721664275466284,
      "grad_norm": 3.4935219287872314,
      "learning_rate": 9.454063981512041e-07,
      "loss": 1.6173,
      "step": 2400
    },
    {
      "epoch": 1.7288378766140604,
      "grad_norm": 4.5346150398254395,
      "learning_rate": 8.981560147718693e-07,
      "loss": 1.5337,
      "step": 2410
    },
    {
      "epoch": 1.7360114777618363,
      "grad_norm": 4.686036109924316,
      "learning_rate": 8.520613151197899e-07,
      "loss": 1.6765,
      "step": 2420
    },
    {
      "epoch": 1.7431850789096126,
      "grad_norm": 4.895930290222168,
      "learning_rate": 8.071281519534202e-07,
      "loss": 1.5393,
      "step": 2430
    },
    {
      "epoch": 1.750358680057389,
      "grad_norm": 3.534666061401367,
      "learning_rate": 7.633622305480359e-07,
      "loss": 1.6068,
      "step": 2440
    },
    {
      "epoch": 1.757532281205165,
      "grad_norm": 4.309584140777588,
      "learning_rate": 7.207691079713364e-07,
      "loss": 1.5728,
      "step": 2450
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 4.053730010986328,
      "learning_rate": 6.793541923778357e-07,
      "loss": 1.5916,
      "step": 2460
    },
    {
      "epoch": 1.7718794835007174,
      "grad_norm": 4.807557106018066,
      "learning_rate": 6.391227423221824e-07,
      "loss": 1.5978,
      "step": 2470
    },
    {
      "epoch": 1.7790530846484935,
      "grad_norm": 3.796672821044922,
      "learning_rate": 6.000798660914731e-07,
      "loss": 1.608,
      "step": 2480
    },
    {
      "epoch": 1.7862266857962696,
      "grad_norm": 4.215502738952637,
      "learning_rate": 5.622305210566304e-07,
      "loss": 1.6484,
      "step": 2490
    },
    {
      "epoch": 1.793400286944046,
      "grad_norm": 4.344812393188477,
      "learning_rate": 5.255795130429575e-07,
      "loss": 1.5738,
      "step": 2500
    },
    {
      "epoch": 1.800573888091822,
      "grad_norm": 4.1684651374816895,
      "learning_rate": 4.901314957199354e-07,
      "loss": 1.5506,
      "step": 2510
    },
    {
      "epoch": 1.8077474892395982,
      "grad_norm": 4.464892387390137,
      "learning_rate": 4.5589097001032423e-07,
      "loss": 1.6428,
      "step": 2520
    },
    {
      "epoch": 1.8149210903873745,
      "grad_norm": 3.725522994995117,
      "learning_rate": 4.228622835186824e-07,
      "loss": 1.5741,
      "step": 2530
    },
    {
      "epoch": 1.8220946915351508,
      "grad_norm": 5.237447738647461,
      "learning_rate": 3.9104962997933095e-07,
      "loss": 1.572,
      "step": 2540
    },
    {
      "epoch": 1.8292682926829267,
      "grad_norm": 4.408272743225098,
      "learning_rate": 3.6045704872386787e-07,
      "loss": 1.6545,
      "step": 2550
    },
    {
      "epoch": 1.836441893830703,
      "grad_norm": 4.324020862579346,
      "learning_rate": 3.310884241682866e-07,
      "loss": 1.63,
      "step": 2560
    },
    {
      "epoch": 1.8436154949784793,
      "grad_norm": 4.20589017868042,
      "learning_rate": 3.029474853197556e-07,
      "loss": 1.6444,
      "step": 2570
    },
    {
      "epoch": 1.8507890961262554,
      "grad_norm": 4.329726696014404,
      "learning_rate": 2.760378053031465e-07,
      "loss": 1.5526,
      "step": 2580
    },
    {
      "epoch": 1.8579626972740315,
      "grad_norm": 3.7564589977264404,
      "learning_rate": 2.503628009073367e-07,
      "loss": 1.6503,
      "step": 2590
    },
    {
      "epoch": 1.8651362984218078,
      "grad_norm": 3.937331199645996,
      "learning_rate": 2.2592573215137415e-07,
      "loss": 1.5755,
      "step": 2600
    },
    {
      "epoch": 1.872309899569584,
      "grad_norm": 4.826626300811768,
      "learning_rate": 2.0272970187054874e-07,
      "loss": 1.6087,
      "step": 2610
    },
    {
      "epoch": 1.87948350071736,
      "grad_norm": 4.709510326385498,
      "learning_rate": 1.8077765532241277e-07,
      "loss": 1.6127,
      "step": 2620
    },
    {
      "epoch": 1.8866571018651364,
      "grad_norm": 4.109603404998779,
      "learning_rate": 1.6007237981281232e-07,
      "loss": 1.6384,
      "step": 2630
    },
    {
      "epoch": 1.8938307030129125,
      "grad_norm": 4.603442192077637,
      "learning_rate": 1.4061650434198492e-07,
      "loss": 1.5609,
      "step": 2640
    },
    {
      "epoch": 1.9010043041606886,
      "grad_norm": 4.087158679962158,
      "learning_rate": 1.241764984876015e-07,
      "loss": 1.5739,
      "step": 2650
    },
    {
      "epoch": 1.9081779053084649,
      "grad_norm": 3.7002909183502197,
      "learning_rate": 1.0710115756589756e-07,
      "loss": 1.5536,
      "step": 2660
    },
    {
      "epoch": 1.9153515064562412,
      "grad_norm": 3.4794106483459473,
      "learning_rate": 9.128194257056244e-08,
      "loss": 1.6448,
      "step": 2670
    },
    {
      "epoch": 1.922525107604017,
      "grad_norm": 3.8147759437561035,
      "learning_rate": 7.672086210659624e-08,
      "loss": 1.6336,
      "step": 2680
    },
    {
      "epoch": 1.9296987087517934,
      "grad_norm": 4.096699237823486,
      "learning_rate": 6.341976503053681e-08,
      "loss": 1.5779,
      "step": 2690
    },
    {
      "epoch": 1.9368723098995697,
      "grad_norm": 4.057299613952637,
      "learning_rate": 5.138034021569982e-08,
      "loss": 1.5193,
      "step": 2700
    },
    {
      "epoch": 1.9440459110473458,
      "grad_norm": 4.358775615692139,
      "learning_rate": 4.060411633774352e-08,
      "loss": 1.6625,
      "step": 2710
    },
    {
      "epoch": 1.951219512195122,
      "grad_norm": 5.0151686668396,
      "learning_rate": 3.109246168056856e-08,
      "loss": 1.4994,
      "step": 2720
    },
    {
      "epoch": 1.9583931133428982,
      "grad_norm": 4.2027764320373535,
      "learning_rate": 2.2846583962577994e-08,
      "loss": 1.5302,
      "step": 2730
    },
    {
      "epoch": 1.9655667144906743,
      "grad_norm": 3.7869021892547607,
      "learning_rate": 1.5867530183339973e-08,
      "loss": 1.5195,
      "step": 2740
    },
    {
      "epoch": 1.9727403156384504,
      "grad_norm": 3.9194717407226562,
      "learning_rate": 1.0156186490637432e-08,
      "loss": 1.5304,
      "step": 2750
    },
    {
      "epoch": 1.9799139167862267,
      "grad_norm": 4.973721027374268,
      "learning_rate": 5.713278067959183e-09,
      "loss": 1.6821,
      "step": 2760
    },
    {
      "epoch": 1.9870875179340028,
      "grad_norm": 4.164020538330078,
      "learning_rate": 2.539369042415807e-09,
      "loss": 1.5994,
      "step": 2770
    },
    {
      "epoch": 1.994261119081779,
      "grad_norm": 3.422834873199463,
      "learning_rate": 6.348624131180536e-10,
      "loss": 1.5436,
      "step": 2780
    },
    {
      "epoch": 2.0,
      "step": 2788,
      "total_flos": 9.303941261898547e+16,
      "train_loss": 1.6751451242602882,
      "train_runtime": 735.9557,
      "train_samples_per_second": 15.15,
      "train_steps_per_second": 3.788
    }
  ],
  "logging_steps": 10,
  "max_steps": 2788,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500.0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.303941261898547e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
